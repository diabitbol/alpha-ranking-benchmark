{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "366aff5b-91cd-4af2-8e81-8f20add55892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b8636e31-7ebc-4cea-b89d-8afc358e8a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../sp500_ohlcv_2005_2025_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dc6d065e-8c35-4139-9994-0f0ff9494933",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Suppose df a les colonnes : Date, Ticker, Open, High, Low, Close, Volume\n",
    "df = df.sort_values([\"Ticker\", \"Date\"])\n",
    "\n",
    "# --- 1) Log-return\n",
    "df[\"log_return\"] = np.log(df[\"Close\"]) - np.log(df[\"Close\"].shift(1))\n",
    "\n",
    "# --- 2) Target direction (r_{t+1} > 0)\n",
    "df[\"target\"] = (df.groupby(\"Ticker\")[\"log_return\"].shift(-1) > 0).astype(int)\n",
    "\n",
    "# --- 3) Features momentum\n",
    "df[\"mom_5\"]  = df.groupby(\"Ticker\")[\"Close\"].transform(lambda x: x / x.shift(5) - 1)\n",
    "df[\"mom_21\"] = df.groupby(\"Ticker\")[\"Close\"].transform(lambda x: x / x.shift(21) - 1)\n",
    "\n",
    "# --- 4) Features volatilité\n",
    "df[\"vol_5\"]  = df.groupby(\"Ticker\")[\"log_return\"].transform(lambda x: x.rolling(5).std())\n",
    "df[\"vol_21\"] = df.groupby(\"Ticker\")[\"log_return\"].transform(lambda x: x.rolling(21).std())\n",
    "\n",
    "# --- 5) High–Low range\n",
    "df[\"range\"] = (df[\"High\"] - df[\"Low\"]) / df[\"Open\"]\n",
    "\n",
    "# --- 6) Volume z-score\n",
    "df[\"volume_z\"] = df.groupby(\"Ticker\")[\"Volume\"].transform(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "\n",
    "df['Return'] = df.groupby('Ticker')['Close'].pct_change(fill_method=None)\n",
    "\n",
    "# --- 7) Clean\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "940909dc-58fd-45fe-9301-8e7a870d2e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56735/543082282.py:9: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(resp.text, header=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>log_return</th>\n",
       "      <th>target</th>\n",
       "      <th>mom_5</th>\n",
       "      <th>mom_21</th>\n",
       "      <th>vol_5</th>\n",
       "      <th>vol_21</th>\n",
       "      <th>range</th>\n",
       "      <th>volume_z</th>\n",
       "      <th>Return</th>\n",
       "      <th>Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2278836</th>\n",
       "      <td>2024-12-24</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>161.553123</td>\n",
       "      <td>162.875546</td>\n",
       "      <td>160.605722</td>\n",
       "      <td>162.540009</td>\n",
       "      <td>1023600.0</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.035658</td>\n",
       "      <td>-0.069281</td>\n",
       "      <td>0.013838</td>\n",
       "      <td>0.011887</td>\n",
       "      <td>0.014050</td>\n",
       "      <td>-0.714869</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278837</th>\n",
       "      <td>2024-12-26</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>161.572877</td>\n",
       "      <td>163.615722</td>\n",
       "      <td>160.882060</td>\n",
       "      <td>163.349274</td>\n",
       "      <td>2167200.0</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.008921</td>\n",
       "      <td>-0.073807</td>\n",
       "      <td>0.011590</td>\n",
       "      <td>0.011660</td>\n",
       "      <td>0.016919</td>\n",
       "      <td>-0.256480</td>\n",
       "      <td>0.004979</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278838</th>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>162.786715</td>\n",
       "      <td>164.345996</td>\n",
       "      <td>161.375477</td>\n",
       "      <td>162.441315</td>\n",
       "      <td>1800100.0</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006605</td>\n",
       "      <td>-0.063176</td>\n",
       "      <td>0.005697</td>\n",
       "      <td>0.011267</td>\n",
       "      <td>0.018248</td>\n",
       "      <td>-0.403625</td>\n",
       "      <td>-0.005558</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278839</th>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>161.740613</td>\n",
       "      <td>161.898519</td>\n",
       "      <td>159.332611</td>\n",
       "      <td>160.112259</td>\n",
       "      <td>1531400.0</td>\n",
       "      <td>-0.014442</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.015773</td>\n",
       "      <td>-0.082041</td>\n",
       "      <td>0.007613</td>\n",
       "      <td>0.011328</td>\n",
       "      <td>0.015864</td>\n",
       "      <td>-0.511328</td>\n",
       "      <td>-0.014338</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278840</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>160.763608</td>\n",
       "      <td>161.602466</td>\n",
       "      <td>159.747117</td>\n",
       "      <td>160.793213</td>\n",
       "      <td>1327400.0</td>\n",
       "      <td>0.004244</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.008218</td>\n",
       "      <td>-0.070300</td>\n",
       "      <td>0.008295</td>\n",
       "      <td>0.011421</td>\n",
       "      <td>0.011541</td>\n",
       "      <td>-0.593097</td>\n",
       "      <td>0.004253</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date Ticker        Open        High         Low       Close  \\\n",
       "2278836  2024-12-24    ZTS  161.553123  162.875546  160.605722  162.540009   \n",
       "2278837  2024-12-26    ZTS  161.572877  163.615722  160.882060  163.349274   \n",
       "2278838  2024-12-27    ZTS  162.786715  164.345996  161.375477  162.441315   \n",
       "2278839  2024-12-30    ZTS  161.740613  161.898519  159.332611  160.112259   \n",
       "2278840  2024-12-31    ZTS  160.763608  161.602466  159.747117  160.793213   \n",
       "\n",
       "            Volume  log_return  target     mom_5    mom_21     vol_5  \\\n",
       "2278836  1023600.0    0.002553       1 -0.035658 -0.069281  0.013838   \n",
       "2278837  2167200.0    0.004967       0 -0.008921 -0.073807  0.011590   \n",
       "2278838  1800100.0   -0.005574       0  0.006605 -0.063176  0.005697   \n",
       "2278839  1531400.0   -0.014442       1 -0.015773 -0.082041  0.007613   \n",
       "2278840  1327400.0    0.004244       0 -0.008218 -0.070300  0.008295   \n",
       "\n",
       "           vol_21     range  volume_z    Return       Sector  \n",
       "2278836  0.011887  0.014050 -0.714869  0.002557  Health Care  \n",
       "2278837  0.011660  0.016919 -0.256480  0.004979  Health Care  \n",
       "2278838  0.011267  0.018248 -0.403625 -0.005558  Health Care  \n",
       "2278839  0.011328  0.015864 -0.511328 -0.014338  Health Care  \n",
       "2278840  0.011421  0.011541 -0.593097  0.004253  Health Care  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "resp = requests.get(url, headers=headers)\n",
    "resp.raise_for_status()  # lève une erreur si 4xx/5xx\n",
    "\n",
    "tables = pd.read_html(resp.text, header=0)\n",
    "sp500 = tables[0]\n",
    "\n",
    "sp500 = sp500.rename(columns={\"Symbol\": \"Ticker\", \"GICS Sector\": \"Sector\"})\n",
    "sp500['Ticker'] = sp500['Ticker'].str.replace('.', '-', regex=False)\n",
    "\n",
    "df = df.sort_values(by=['Ticker', 'Date'])\n",
    "\n",
    "df = df.merge(\n",
    "    sp500[['Ticker', 'Sector']], \n",
    "    on='Ticker', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a8530e-39e0-43c5-8fa7-e606bae87bcf",
   "metadata": {},
   "source": [
    "la variable Sector est catégorielle par conséquent on va l'encoder par par la volatilité moyenne du secteur. Ce choix est motivé par la raison suivante. On veut faire comprendre au modèle que certains secteurs sont très volatils et très dépendants de chocs extérieur ainsi pour ces secteurs la, l'évolution futur de l'action est moins évidente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d4eeb5fe-ae7b-4325-922b-40b1b663205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Calcul de volatilité moyenne par secteur\n",
    "sector_vol_mean = df.groupby(\"Sector\")[\"vol_21\"].mean()\n",
    "\n",
    "# 2) Encodage de Sector par cette moyenne\n",
    "df[\"Sector_encoded\"] = df[\"Sector\"].map(sector_vol_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dc960f06-bac8-409b-8a61-8424f1786a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "def classification_logreg(df, features, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Classification binaire via régression logistique, avec split temporel et métriques globales\n",
    "    + métrique par secteur.\n",
    "\n",
    "    Split temporel (chronologique) :\n",
    "      - train : Date < 2018-01-01\n",
    "      - val   : 2018-01-01 <= Date < 2021-01-01  (préparé mais non utilisé ici)\n",
    "      - test  : Date >= 2021-01-01\n",
    "\n",
    "    Le modèle apprend P(target=1 | X). On convertit ensuite en classe via un seuil `threshold`.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Doit contenir : \"Date\", \"target\", \"Sector\" + les colonnes de `features`.\n",
    "        Ici `target` doit être binaire (0/1).\n",
    "    features : list[str]\n",
    "        Colonnes explicatives.\n",
    "    threshold : float, par défaut 0.5\n",
    "        Seuil de décision : y_pred = 1 si proba > threshold.\n",
    "\n",
    "    Retours\n",
    "    -------\n",
    "    model : LogisticRegression\n",
    "        Modèle entraîné.\n",
    "    sector_accuracy : pd.Series\n",
    "        Accuracy par secteur, triée décroissante.\n",
    "    \"\"\"\n",
    "\n",
    "    # Copie défensive pour ne pas modifier df\n",
    "    df = df.copy()\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 1) Split train/val/test (chronologique)\n",
    "    # ----------------------------------------\n",
    "    train = df[df[\"Date\"] < \"2018-01-01\"]\n",
    "    val   = df[(df[\"Date\"] >= \"2018-01-01\") & (df[\"Date\"] < \"2021-01-01\")]\n",
    "    test  = df[df[\"Date\"] >= \"2021-01-01\"].copy()  # copy important car on ajoute \"pred\"\n",
    "\n",
    "    X_train, y_train = train[features], train[\"target\"]\n",
    "    X_val,   y_val   = val[features],   val[\"target\"]   # non utilisé ici (mais utile pour tuning/threshold)\n",
    "    X_test,  y_test  = test[features],  test[\"target\"]\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 2) Entraînement du modèle\n",
    "    # ----------------------------------------\n",
    "    # max_iter augmenté pour éviter les non-convergences sur gros jeux de données.\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 3) Prédiction : proba puis classe via seuil\n",
    "    # ----------------------------------------\n",
    "    # predict_proba renvoie [P(class=0), P(class=1)] ; on garde la proba de la classe 1\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Binarisation selon le seuil\n",
    "    y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 4) Métriques globales\n",
    "    # ----------------------------------------\n",
    "    # Accuracy globale sur le test\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy :\", acc)\n",
    "\n",
    "    # (Optionnel mais souvent utile en finance / classes déséquilibrées)\n",
    "    # - AUC : qualité de ranking des probabilités (indépendant du seuil)\n",
    "    # - F1  : compromis précision/rappel (utile si classe 1 rare)\n",
    "    # - confusion matrix / report : diagnostic complet\n",
    "    # On ne print pas tout par défaut, mais tu peux décommenter au besoin.\n",
    "    # auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    # f1  = f1_score(y_test, y_pred)\n",
    "    # print(\"AUC      :\", auc)\n",
    "    # print(\"F1       :\", f1)\n",
    "    # print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # On stocke la prédiction dans test pour calculer des métriques par groupe\n",
    "    test[\"pred\"] = y_pred\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 5) Métrique par secteur\n",
    "    # ----------------------------------------\n",
    "    sector_accuracy = (\n",
    "        test.groupby(\"Sector\")\n",
    "            .apply(lambda g: accuracy_score(g[\"target\"], g[\"pred\"]), include_groups=False)\n",
    "            .sort_values(ascending=False)\n",
    "    )\n",
    "\n",
    "    return model, sector_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3226df3a-a957-4d54-b03f-c582a7f4cdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.5177679134039983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(max_iter=1000),\n",
       " Sector\n",
       " Financials                0.524993\n",
       " Utilities                 0.521979\n",
       " Industrials               0.521291\n",
       " Real Estate               0.520815\n",
       " Energy                    0.518289\n",
       " Information Technology    0.516843\n",
       " Consumer Staples          0.516080\n",
       " Consumer Discretionary    0.515701\n",
       " Health Care               0.511678\n",
       " Communication Services    0.509799\n",
       " Materials                 0.506109\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression(df, [\"mom_5\", \"mom_21\", \"vol_5\", \"vol_21\", \"range\", \"volume_z\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0fb1b4-12e1-41e9-8e6e-4ad976f6b55c",
   "metadata": {},
   "source": [
    "De premier abord, la regression parait ne pas être suffisante pour prédire le signe du rendement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c66424cc-4463-4918-a7c1-40bdc908433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "def training_xgb_classifier(df, features, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Entraîne un classifieur XGBoost (XGBClassifier) sur une cible binaire `target`,\n",
    "    avec un split temporel (train/val/test), puis évalue sur le test et calcule une\n",
    "    métrique par secteur.\n",
    "\n",
    "    Split temporel :\n",
    "      - train : Date < 2018-01-01\n",
    "      - val   : 2018-01-01 <= Date < 2021-01-01   (utilisé pour le suivi pendant fit)\n",
    "      - test  : Date >= 2021-01-01\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Doit contenir : \"Date\", \"target\", \"Sector\" + les colonnes de `features`.\n",
    "        `target` doit être binaire (0/1).\n",
    "    features : list[str]\n",
    "        Colonnes explicatives.\n",
    "    threshold : float, par défaut 0.5\n",
    "        Seuil de décision sur la probabilité de classe 1.\n",
    "\n",
    "    Retours\n",
    "    -------\n",
    "    sector_accuracy : pd.Series\n",
    "        Accuracy par secteur sur le test (triée décroissante).\n",
    "    \"\"\"\n",
    "\n",
    "    # Copie défensive pour ne pas modifier l'objet df en entrée\n",
    "    df = df.copy()\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 1) Split train/val/test (chronologique)\n",
    "    # ----------------------------------------\n",
    "    train = df[df[\"Date\"] < \"2018-01-01\"]\n",
    "    val   = df[(df[\"Date\"] >= \"2018-01-01\") & (df[\"Date\"] < \"2021-01-01\")]\n",
    "    test  = df[df[\"Date\"] >= \"2021-01-01\"].copy()  # copy car on ajoute ensuite \"pred\"\n",
    "\n",
    "    X_train, y_train = train[features], train[\"target\"]\n",
    "    X_val,   y_val   = val[features],   val[\"target\"]\n",
    "    X_test,  y_test  = test[features],  test[\"target\"]\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 2) Modèle XGBoost (classification)\n",
    "    # ----------------------------------------\n",
    "    # Hyperparamètres :\n",
    "    # - max_depth : complexité des arbres\n",
    "    # - learning_rate : shrinkage (plus faible => + d'arbres)\n",
    "    # - n_estimators : nombre max d'arbres (pas d'early stopping ici)\n",
    "    # - subsample / colsample_bytree : bagging pour régulariser\n",
    "    #\n",
    "    # NB : tu peux aussi fixer random_state pour reproductibilité.\n",
    "    model = xgb.XGBClassifier(\n",
    "        max_depth=5,\n",
    "        learning_rate=0.03,\n",
    "        n_estimators=800,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric=\"logloss\",  # évite warnings et définit la métrique suivie sur eval_set\n",
    "    )\n",
    "\n",
    "    # Entraînement (val fourni pour monitoring, mais sans early stopping ici)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 3) Prédiction (proba -> classe via seuil)\n",
    "    # ----------------------------------------\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 4) Métriques globales (test)\n",
    "    # ----------------------------------------\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy :\", acc)\n",
    "\n",
    "    # Optionnel : utile si classes déséquilibrées\n",
    "    # f1  = f1_score(y_test, y_pred)\n",
    "    # auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    # print(\"F1       :\", f1)\n",
    "    # print(\"AUC      :\", auc)\n",
    "    # print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Ajout des prédictions pour calculs par groupe\n",
    "    test[\"pred\"] = y_pred\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 5) Métrique par secteur\n",
    "    # ----------------------------------------\n",
    "    sector_accuracy = (\n",
    "        test.groupby(\"Sector\")\n",
    "            .apply(lambda g: accuracy_score(g[\"target\"], g[\"pred\"]), include_groups=False)\n",
    "            .sort_values(ascending=False)\n",
    "    )\n",
    "\n",
    "    return sector_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ea988d9-422c-4945-8cd3-b7b8552965f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.5128854497365115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sector\n",
       "Financials                0.518164\n",
       "Utilities                 0.517800\n",
       "Real Estate               0.516996\n",
       "Information Technology    0.515275\n",
       "Materials                 0.515144\n",
       "Industrials               0.512890\n",
       "Energy                    0.512804\n",
       "Consumer Staples          0.511582\n",
       "Communication Services    0.507419\n",
       "Health Care               0.506284\n",
       "Consumer Discretionary    0.506053\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training(df, [\"Close\", \"mom_5\", \"mom_21\", \"vol_5\", \"vol_21\", \"range\", \"volume_z\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9559d6e7-1420-4a83-8dad-4ad27af0f007",
   "metadata": {},
   "source": [
    "meme en ajoutant des variable pertinentes, l'accuracy reste sensiblement la meme peu importe le secteur. L'accuracy réalisée est 0.51. Peut etre qu'étant donné le fait que les années d'entrainement sont très anciennes par rapport aux années de test le modèle est mal adapté aux nouvelles années\n",
    "\n",
    "Changeons de méthode d'entrainement : éparpillons des années de test et de validation dans tous le dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84424a1f-6964-4485-a24b-a7928c649644",
   "metadata": {},
   "source": [
    "# Ajout de la variable secteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c5297153-47bc-467e-b552-328f48b2055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "def training2_xgb_classifier(df, features, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Variante de training XGBoost classification avec un split \"en blocs alternés\" :\n",
    "    on alterne des fenêtres temporelles pour train / val / test sur plusieurs périodes.\n",
    "\n",
    "    Objectif typique :\n",
    "    - évaluer la robustesse du modèle sur plusieurs régimes de marché (plusieurs cycles),\n",
    "      plutôt qu'un seul bloc train->test.\n",
    "    - éviter que tout le test soit concentré sur une seule période (ex: uniquement 2021+).\n",
    "\n",
    "    Train :\n",
    "      - 2004-01-01 .. 2008-01-01\n",
    "      - 2010-01-01 .. 2013-01-01\n",
    "      - 2015-01-01 .. 2018-01-01\n",
    "      - 2020-01-01 .. 2023-01-01\n",
    "\n",
    "    Val :\n",
    "      - 2008-01-01 .. 2009-01-01\n",
    "      - 2013-01-01 .. 2014-01-01\n",
    "      - 2018-01-01 .. 2019-01-01\n",
    "      - 2023-01-01 .. 2024-01-01\n",
    "\n",
    "    Test :\n",
    "      - 2009-01-01 .. 2010-01-01\n",
    "      - 2014-01-01 .. 2015-01-01\n",
    "      - 2019-01-01 .. 2020-01-01\n",
    "      - 2024-01-01 .. 2025-01-01\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Doit contenir : \"Date\", \"target\", \"Sector\" + features.\n",
    "        `target` doit être binaire (0/1).\n",
    "    features : list[str]\n",
    "        Colonnes explicatives.\n",
    "    threshold : float, par défaut 0.5\n",
    "        Seuil proba -> classe.\n",
    "\n",
    "    Retours\n",
    "    -------\n",
    "    sector_accuracy : pd.Series\n",
    "        Accuracy par secteur sur l'ensemble test (toutes fenêtres confondues), triée décroissante.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 1) Construction des masques temporels (train / val / test)\n",
    "    # ------------------------------------------------------------\n",
    "    # .between(a, b) est inclusif des deux côtés (>=a et <=b).\n",
    "    # Ici, ça peut créer des chevauchements aux bornes si tu n'es pas attentif.\n",
    "    # (ex: une date = \"2008-01-01\" appartient à la fois à train et val)\n",
    "    #\n",
    "    # Si tu veux éviter *tout* overlap, il faut rendre les bornes disjointes\n",
    "    # (par ex. utiliser < sur la borne haute).\n",
    "    mask_train = (\n",
    "        df[\"Date\"].between(\"2004-01-01\", \"2008-01-01\") |\n",
    "        df[\"Date\"].between(\"2010-01-01\", \"2013-01-01\") |\n",
    "        df[\"Date\"].between(\"2015-01-01\", \"2018-01-01\") |\n",
    "        df[\"Date\"].between(\"2020-01-01\", \"2023-01-01\")\n",
    "    )\n",
    "\n",
    "    mask_val = (\n",
    "        df[\"Date\"].between(\"2008-01-01\", \"2009-01-01\") |\n",
    "        df[\"Date\"].between(\"2013-01-01\", \"2014-01-01\") |\n",
    "        df[\"Date\"].between(\"2018-01-01\", \"2019-01-01\") |\n",
    "        df[\"Date\"].between(\"2023-01-01\", \"2024-01-01\")\n",
    "    )\n",
    "\n",
    "    mask_test = (\n",
    "        df[\"Date\"].between(\"2009-01-01\", \"2010-01-01\") |\n",
    "        df[\"Date\"].between(\"2014-01-01\", \"2015-01-01\") |\n",
    "        df[\"Date\"].between(\"2019-01-01\", \"2020-01-01\") |\n",
    "        df[\"Date\"].between(\"2024-01-01\", \"2025-01-01\")\n",
    "    )\n",
    "\n",
    "    train = df.loc[mask_train]\n",
    "    val   = df.loc[mask_val]\n",
    "    test  = df.loc[mask_test].copy()  # copy car on ajoute \"pred\" ensuite\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 2) Matrices X / y\n",
    "    # ------------------------------------------------------------\n",
    "    X_train, y_train = train[features], train[\"target\"]\n",
    "    X_val,   y_val   = val[features],   val[\"target\"]\n",
    "    X_test,  y_test  = test[features],  test[\"target\"]\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 3) Modèle XGBoost (classification)\n",
    "    # ------------------------------------------------------------\n",
    "    model = xgb.XGBClassifier(\n",
    "        max_depth=5,\n",
    "        learning_rate=0.03,\n",
    "        n_estimators=800,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric=\"logloss\",\n",
    "    )\n",
    "\n",
    "    # Entraînement (val pour monitoring, sans early stopping explicite ici)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 4) Prédiction sur test\n",
    "    # ------------------------------------------------------------\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "    # Stockage pour métriques par groupe\n",
    "    test[\"pred\"] = y_pred\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 5) Métriques globales\n",
    "    # ------------------------------------------------------------\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy :\", acc)\n",
    "\n",
    "    # Optionnel\n",
    "    # f1  = f1_score(y_test, y_pred)\n",
    "    # auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    # print(\"F1       :\", f1)\n",
    "    # print(\"AUC      :\", auc)\n",
    "    # print(confusion_matrix(y_test, y_pred))\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 6) Métrique par secteur\n",
    "    # ------------------------------------------------------------\n",
    "    sector_accuracy = (\n",
    "        test.groupby(\"Sector\")\n",
    "            .apply(lambda g: accuracy_score(g[\"target\"], g[\"pred\"]), include_groups=False)\n",
    "            .sort_values(ascending=False)\n",
    "    )\n",
    "\n",
    "    return sector_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dba4301c-1bd7-46d1-8b4b-585e8515aa4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.5285094832442767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sector\n",
       "Real Estate               0.541369\n",
       "Utilities                 0.538882\n",
       "Materials                 0.535286\n",
       "Financials                0.535254\n",
       "Industrials               0.529979\n",
       "Information Technology    0.527850\n",
       "Consumer Staples          0.524530\n",
       "Health Care               0.521683\n",
       "Communication Services    0.518975\n",
       "Consumer Discretionary    0.518429\n",
       "Energy                    0.516915\n",
       "dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training2(df, [\"mom_21\", \"vol_21\", \"range\", \"volume_z\", \"Sector_encoded\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91cf75f-8d4d-4cfd-afd4-829c36abc3d7",
   "metadata": {},
   "source": [
    "la meilleur accuracy est meilleure que celle obtenue précédemment 0.5293 mais reste cependant faible. \n",
    "\n",
    "Essayons de préciser nos modèles en les concentrant sur un secteur. Peut être que les modèles précédent essayaient de trop généraliser ce qui les rendait imprécis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ccba9f99-93e6-4865-a593-2696e70bf9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "def training3_xgb_classifier_sector(df, features, sector, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Entraîne un XGBoost classifier *uniquement* sur un secteur donné, en utilisant\n",
    "    un split temporel \"en blocs alternés\" (train/val/test sur plusieurs fenêtres).\n",
    "\n",
    "    Différence avec `training2` :\n",
    "    - Ici on filtre d'abord (implicitement via les masques) sur `Sector == sector`,\n",
    "      donc le modèle est spécifique à un secteur.\n",
    "\n",
    "    Train :\n",
    "      - 2004-01-01 .. 2008-01-01\n",
    "      - 2010-01-01 .. 2013-01-01\n",
    "      - 2015-01-01 .. 2018-01-01\n",
    "      - 2020-01-01 .. 2023-01-01\n",
    "\n",
    "    Val :\n",
    "      - 2008-01-01 .. 2009-01-01\n",
    "      - 2013-01-01 .. 2014-01-01\n",
    "      - 2018-01-01 .. 2019-01-01\n",
    "      - 2023-01-01 .. 2024-01-01\n",
    "\n",
    "    Test :\n",
    "      - 2009-01-01 .. 2010-01-01\n",
    "      - 2014-01-01 .. 2015-01-01\n",
    "      - 2019-01-01 .. 2020-01-01\n",
    "      - 2024-01-01 .. 2025-01-01\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Doit contenir : \"Date\", \"Sector\", \"target\" + features.\n",
    "        `target` doit être binaire (0/1).\n",
    "    features : list[str]\n",
    "        Variables explicatives.\n",
    "    sector : str\n",
    "        Valeur de la colonne \"Sector\" à sélectionner (ex: \"Information Technology\").\n",
    "    threshold : float, par défaut 0.5\n",
    "        Seuil proba -> classe.\n",
    "\n",
    "    Retours\n",
    "    -------\n",
    "    metrics : dict\n",
    "        Dictionnaire de métriques utiles pour ce secteur :\n",
    "        - \"sector\" : secteur\n",
    "        - \"accuracy\" : accuracy globale sur test\n",
    "        - \"n_train\", \"n_val\", \"n_test\" : tailles des splits\n",
    "        - \"model\" : modèle entraîné\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 1) Masques temporels + filtre sector\n",
    "    # ------------------------------------------------------------\n",
    "    mask_train = (\n",
    "        (df[\"Sector\"] == sector) &\n",
    "        (\n",
    "            df[\"Date\"].between(\"2004-01-01\", \"2008-01-01\") |\n",
    "            df[\"Date\"].between(\"2010-01-01\", \"2013-01-01\") |\n",
    "            df[\"Date\"].between(\"2015-01-01\", \"2018-01-01\") |\n",
    "            df[\"Date\"].between(\"2020-01-01\", \"2023-01-01\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    mask_val = (\n",
    "        (df[\"Sector\"] == sector) &\n",
    "        (\n",
    "            df[\"Date\"].between(\"2008-01-01\", \"2009-01-01\") |\n",
    "            df[\"Date\"].between(\"2013-01-01\", \"2014-01-01\") |\n",
    "            df[\"Date\"].between(\"2018-01-01\", \"2019-01-01\") |\n",
    "            df[\"Date\"].between(\"2023-01-01\", \"2024-01-01\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    mask_test = (\n",
    "        (df[\"Sector\"] == sector) &\n",
    "        (\n",
    "            df[\"Date\"].between(\"2009-01-01\", \"2010-01-01\") |\n",
    "            df[\"Date\"].between(\"2014-01-01\", \"2015-01-01\") |\n",
    "            df[\"Date\"].between(\"2019-01-01\", \"2020-01-01\") |\n",
    "            df[\"Date\"].between(\"2024-01-01\", \"2025-01-01\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    train = df.loc[mask_train]\n",
    "    val   = df.loc[mask_val]\n",
    "    test  = df.loc[mask_test].copy()\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 2) Matrices X / y\n",
    "    # ------------------------------------------------------------\n",
    "    X_train, y_train = train[features], train[\"target\"]\n",
    "    X_val,   y_val   = val[features],   val[\"target\"]\n",
    "    X_test,  y_test  = test[features],  test[\"target\"]\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 3) Modèle XGBoost (classification)\n",
    "    # ------------------------------------------------------------\n",
    "    model = xgb.XGBClassifier(\n",
    "        max_depth=5,\n",
    "        learning_rate=0.03,\n",
    "        n_estimators=800,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric=\"logloss\",\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 4) Prédictions et métriques (test)\n",
    "    # ------------------------------------------------------------\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy :\", acc)\n",
    "\n",
    "    # Optionnel :\n",
    "    # f1  = f1_score(y_test, y_pred)\n",
    "    # auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    return {\n",
    "        \"sector\": sector,\n",
    "        \"accuracy\": acc,\n",
    "        \"n_train\": len(train),\n",
    "        \"n_val\": len(val),\n",
    "        \"n_test\": len(test),\n",
    "        \"model\": model,\n",
    "        # \"f1\": f1,\n",
    "        # \"auc\": auc,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "12f21ad9-07fb-4d44-a554-2f1394eef58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.5264772575696945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sector\n",
       "Utilities    0.526477\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training3(df, [\"mom_5\", \"vol_5\", \"range\", \"volume_z\", \"mom_21\"], \"Utilities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9f1b3193-cc0c-4f0d-9c17-36d1903d0794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "def training4_xgb_classifier_ticker(df, features, ticker, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Entraîne un XGBoost classifier *uniquement* sur un ticker donné, avec un split temporel\n",
    "    \"en blocs alternés\" (plusieurs fenêtres train/val/test).\n",
    "\n",
    "    Train :\n",
    "      - 2004-01-01 .. 2008-01-01\n",
    "      - 2010-01-01 .. 2013-01-01\n",
    "      - 2015-01-01 .. 2018-01-01\n",
    "      - 2020-01-01 .. 2023-01-01\n",
    "\n",
    "    Val :\n",
    "      - 2008-01-01 .. 2009-01-01\n",
    "      - 2013-01-01 .. 2014-01-01\n",
    "      - 2018-01-01 .. 2019-01-01\n",
    "      - 2023-01-01 .. 2024-01-01\n",
    "\n",
    "    Test :\n",
    "      - 2009-01-01 .. 2010-01-01\n",
    "      - 2014-01-01 .. 2015-01-01\n",
    "      - 2019-01-01 .. 2020-01-01\n",
    "      - 2024-01-01 .. 2025-01-01\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Doit contenir : \"Date\", \"Ticker\", \"target\" + features.\n",
    "        `target` doit être binaire (0/1).\n",
    "    features : list[str]\n",
    "        Colonnes explicatives.\n",
    "    ticker : str\n",
    "        Ticker à sélectionner (ex: \"AAPL\").\n",
    "    threshold : float, par défaut 0.5\n",
    "        Seuil de décision sur la probabilité de la classe 1.\n",
    "\n",
    "    Retours\n",
    "    -------\n",
    "    results : dict\n",
    "        Résultats centrés sur CE ticker :\n",
    "        - \"ticker\" : ticker\n",
    "        - \"accuracy\" : accuracy globale sur test\n",
    "        - \"n_train\", \"n_val\", \"n_test\" : tailles\n",
    "        - \"model\" : modèle entraîné\n",
    "\n",
    "    Notes importantes\n",
    "    -----------------\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 1) Masques temporels + filtre ticker\n",
    "    # ------------------------------------------------------------\n",
    "    mask_train = (\n",
    "        (df[\"Ticker\"] == ticker) &\n",
    "        (\n",
    "            df[\"Date\"].between(\"2004-01-01\", \"2008-01-01\") |\n",
    "            df[\"Date\"].between(\"2010-01-01\", \"2013-01-01\") |\n",
    "            df[\"Date\"].between(\"2015-01-01\", \"2018-01-01\") |\n",
    "            df[\"Date\"].between(\"2020-01-01\", \"2023-01-01\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    mask_val = (\n",
    "        (df[\"Ticker\"] == ticker) &\n",
    "        (\n",
    "            df[\"Date\"].between(\"2008-01-01\", \"2009-01-01\") |\n",
    "            df[\"Date\"].between(\"2013-01-01\", \"2014-01-01\") |\n",
    "            df[\"Date\"].between(\"2018-01-01\", \"2019-01-01\") |\n",
    "            df[\"Date\"].between(\"2023-01-01\", \"2024-01-01\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    mask_test = (\n",
    "        (df[\"Ticker\"] == ticker) &\n",
    "        (\n",
    "            df[\"Date\"].between(\"2009-01-01\", \"2010-01-01\") |\n",
    "            df[\"Date\"].between(\"2014-01-01\", \"2015-01-01\") |\n",
    "            df[\"Date\"].between(\"2019-01-01\", \"2020-01-01\") |\n",
    "            df[\"Date\"].between(\"2024-01-01\", \"2025-01-01\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    train = df.loc[mask_train]\n",
    "    val   = df.loc[mask_val]\n",
    "    test  = df.loc[mask_test].copy()\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 2) Matrices X / y\n",
    "    # ------------------------------------------------------------\n",
    "    X_train, y_train = train[features], train[\"target\"]\n",
    "    X_val,   y_val   = val[features],   val[\"target\"]\n",
    "    X_test,  y_test  = test[features],  test[\"target\"]\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 3) Modèle XGBoost (classification)\n",
    "    # ------------------------------------------------------------\n",
    "    model = xgb.XGBClassifier(\n",
    "        max_depth=5,\n",
    "        learning_rate=0.03,\n",
    "        n_estimators=800,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric=\"logloss\",\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 4) Prédictions et métriques (test)\n",
    "    # ------------------------------------------------------------\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy :\", acc)\n",
    "\n",
    "    # Optionnel :\n",
    "    # f1  = f1_score(y_test, y_pred)\n",
    "    # auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    return {\n",
    "        \"ticker\": ticker,\n",
    "        \"accuracy\": acc,\n",
    "        \"n_train\": len(train),\n",
    "        \"n_val\": len(val),\n",
    "        \"n_test\": len(test),\n",
    "        \"model\": model,\n",
    "        # \"f1\": f1,\n",
    "        # \"auc\": auc,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "72797508-f942-455a-b9c8-b7f7ad60937a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.5099206349206349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sector\n",
       "Communication Services    0.509921\n",
       "dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training4(df, [\"mom_5\", \"vol_5\", \"range\", \"volume_z\", \"mom_21\"], \"GOOGL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3d537e5a-9322-4050-9bf3-ca8f93e6576b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.5277777777777778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sector\n",
       "Energy    0.527778\n",
       "dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training4(df, [\"mom_5\", \"vol_5\", \"range\", \"volume_z\", \"mom_21\"], \"XOM\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c79e22-bd8c-42e1-b4d1-788cbded1a0d",
   "metadata": {},
   "source": [
    "On remarque que souvent la catégories la moins bien prédites est celle de l'énergie qui est le secteur le plus sensible au choc d'après ce qui a été vu précédemment. Peut être que le faible score provient des période de crises dues à des chocs extérieurs aux marché qui sont imprévisibles à l'aide 'uniquement les données. Essayons de se limiter à la période la plus calme de 2005-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "97997238-b567-4ed8-aae2-0fb26866d67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "def training5_xgb_classifier(df, features, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Entraîne un XGBoost classifier sur une fenêtre temporelle courte, avec split simple :\n",
    "\n",
    "      - train : 2010-01-01 .. 2012-01-01\n",
    "      - val   : 2012-01-01 .. 2013-01-01\n",
    "      - test  : 2013-01-01 .. 2014-01-01\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Doit contenir : \"Date\", \"target\", \"Sector\" + features.\n",
    "        `target` doit être binaire (0/1).\n",
    "    features : list[str]\n",
    "        Colonnes explicatives.\n",
    "    threshold : float, par défaut 0.5\n",
    "        Seuil de décision pour convertir la proba en classe.\n",
    "\n",
    "    Retours\n",
    "    -------\n",
    "    sector_accuracy : pd.Series\n",
    "        Accuracy par secteur sur le test (triée décroissante).\n",
    "        (Ton code original appelle ça sector_f1 mais calcule accuracy_score.)\n",
    "\n",
    "    Remarques\n",
    "    ---------\n",
    "    - `between(a, b)` inclut les bornes => \"2012-01-01\" peut être dans train ET val,\n",
    "      et \"2013-01-01\" peut être dans val ET test. Si tu veux éviter tout overlap,\n",
    "      préfère des intervalles [a, b) (borne haute exclusive).\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 1) Split temporel (attention aux bornes inclusives)\n",
    "    # ------------------------------------------------------------\n",
    "    mask_train = df[\"Date\"].between(\"2010-01-01\", \"2012-01-01\")\n",
    "    mask_val   = df[\"Date\"].between(\"2012-01-01\", \"2013-01-01\")\n",
    "    mask_test  = df[\"Date\"].between(\"2013-01-01\", \"2014-01-01\")\n",
    "\n",
    "    train = df.loc[mask_train]\n",
    "    val   = df.loc[mask_val]\n",
    "    test  = df.loc[mask_test].copy()\n",
    "\n",
    "    X_train, y_train = train[features], train[\"target\"]\n",
    "    X_val,   y_val   = val[features],   val[\"target\"]\n",
    "    X_test,  y_test  = test[features],  test[\"target\"]\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 2) Modèle XGBoost (classification)\n",
    "    # ------------------------------------------------------------\n",
    "    model = xgb.XGBClassifier(\n",
    "        max_depth=5,\n",
    "        learning_rate=0.03,\n",
    "        n_estimators=800,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric=\"logloss\",\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 3) Prédictions sur test\n",
    "    # ------------------------------------------------------------\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "    # Stockage pour métriques par groupe\n",
    "    test[\"pred\"] = y_pred\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 4) Métrique globale\n",
    "    # ------------------------------------------------------------\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy :\", acc)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 5) Métrique par secteur\n",
    "    # ------------------------------------------------------------\n",
    "    # Attention : ton code l'appelle sector_f1 mais calcule accuracy_score.\n",
    "    sector_accuracy = (\n",
    "        test.groupby(\"Sector\")\n",
    "            .apply(lambda g: accuracy_score(g[\"target\"], g[\"pred\"]), include_groups=False)\n",
    "            .sort_values(ascending=False)\n",
    "    )\n",
    "\n",
    "    return sector_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d441a272-c7c1-46d5-99bc-d4885a0305a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.5262041088323235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sector\n",
       "Materials                 0.541235\n",
       "Industrials               0.531409\n",
       "Consumer Staples          0.530544\n",
       "Health Care               0.529594\n",
       "Financials                0.529561\n",
       "Information Technology    0.527334\n",
       "Consumer Discretionary    0.525391\n",
       "Communication Services    0.520982\n",
       "Utilities                 0.516694\n",
       "Energy                    0.513228\n",
       "Real Estate               0.505200\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training5(df, [\"mom_5\", \"vol_5\", \"range\", \"volume_z\", \"mom_21\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed447d3-f7b7-4400-8a42-d38e40cd23f0",
   "metadata": {},
   "source": [
    "Malheuresement les résultats ne sont pas sensiblement meilleur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4d14de-1701-46cb-b005-8e20a3ad756f",
   "metadata": {},
   "source": [
    "## Interprétation d’une accuracy proche de 51 % et intérêt d’un passage de la classification à la régression\n",
    "\n",
    "### Contexte\n",
    "On considère un problème de classification binaire où l’on cherche à prédire le signe du rendement futur :\n",
    "$$\n",
    "y_{t+h} = \\mathbb{1}_{\\{r_{t+h} > 0\\}},\n",
    "$$\n",
    "à partir d’un vecteur de caractéristiques $X_t$. Les différents modèles testés (régression logistique, classifieurs XGBoost, variantes de découpages temporels) conduisent à une accuracy hors-échantillon proche de 51 %.\n",
    "\n",
    "### 1) Que signifie une accuracy proche de 51 % ?\n",
    "Une accuracy d’environ 51 % doit être interprétée relativement à une référence. Lorsque la proportion de rendements positifs est proche de 50 %, une stratégie aléatoire ou un classifieur constant (par exemple « toujours positif ») obtient typiquement une accuracy autour de 50 %. Un résultat à 51 % indique donc un pouvoir prédictif très faible sur le signe du rendement, ce qui est cohérent avec plusieurs faits stylisés en finance :\n",
    "\n",
    "- Faible prévisibilité du signe à court horizon. Les rendements à fréquence journalière ou hebdomadaire sont dominés par du bruit et par des chocs difficiles à anticiper.\n",
    "- Instabilité de l’étiquette au voisinage de zéro. Une part importante des rendements est proche de 0, si bien qu’une variation marginale (ou un bruit de mesure) peut faire basculer l’étiquette de 0 à 1, rendant la variable cible fragile.\n",
    "- Dépendances temporelles et régimes de marché. Le caractère non stationnaire (changements de volatilité, cycles, crises) réduit la stabilité de la relation $X_t \\mapsto y_{t+h}$ hors-échantillon.\n",
    "\n",
    "Ainsi, une accuracy proche de 50 % n’implique pas nécessairement que les caractéristiques $X_t$ sont inutiles en toute généralité ; elle suggère plutôt que, sous cette formulation, le signe du rendement est un objet particulièrement difficile à prédire et que l’information contenue dans $X_t$ est au mieux marginale à l’horizon étudié.\n",
    "\n",
    "### 2) Limites conceptuelles du cadrage « classification : rendement positif ou non »\n",
    "Transformer un rendement continu $r_{t+h}$ en une variable binaire $y_{t+h}$ réduit fortement l’information disponible.\n",
    "\n",
    "1. Perte de l’information de magnitude. Les observations $r = 0.01\\%$ et $r = 3\\%$ reçoivent le même label $y=1$, alors que leurs implications économiques sont très différentes. De même, $r = -0.01\\%$ et $r = -4\\%$ reçoivent le même label $y=0$. Or la magnitude des mouvements influence directement performance et risque.\n",
    "\n",
    "2. Seuil de décision économiquement arbitraire. Le seuil 0 n’intègre pas les coûts de transaction (spread, commission, slippage). Un rendement légèrement positif peut être non exploitable une fois les coûts pris en compte. Optimiser une fonction de perte centrée sur $\\mathbb{1}_{\\{r_{t+h}>0\\}}$ peut donc être mal aligné avec un objectif économique.\n",
    "\n",
    "3. Métrique d’évaluation potentiellement inadéquate. L’accuracy pénalise de façon identique toutes les erreurs, indépendamment de l’ampleur du mouvement manqué. En finance, se tromper sur un mouvement extrême a généralement un coût économique plus élevé que se tromper sur une variation quasi nulle.\n",
    "\n",
    "### 3) Pourquoi reformuler le problème en régression peut être plus pertinent\n",
    "Une alternative consiste à prédire directement le rendement (ou une transformation du rendement) :\n",
    "$$\n",
    "\\hat r_{t+h} \\approx \\mathbb{E}\\!\\left[r_{t+h}\\mid X_t\\right].\n",
    "$$\n",
    "Cette reformulation présente plusieurs avantages.\n",
    "\n",
    "1. Alignement avec l’objectif économique. L’objet central en allocation d’actifs est l’espérance conditionnelle du rendement (éventuellement ajustée du risque). Une prédiction continue $\\hat r_{t+h}$ peut être utilisée comme score pour construire des positions (pondérations proportionnelles au signal, ou sélection via ranking), ce qui correspond davantage à une logique de portefeuille.\n",
    "\n",
    "2. Exploitation de l’information de magnitude. La régression conserve la granularité des valeurs : le modèle est incité à distinguer des scénarios économiquement différents, plutôt que de uniquement franchir un seuil.\n",
    "\n",
    "3. Règles de décision plus robustes que « $r>0$ ». À partir d’un score continu, il est possible d’éviter la zone la plus bruitée autour de zéro, par exemple :\n",
    "- prendre des positions uniquement sur les quantiles extrêmes (top et bottom),\n",
    "- imposer un seuil $c>0$ reflétant coûts et marge de sécurité, via une règle du type $\\hat r_{t+h} > c$,\n",
    "- utiliser un score ajusté du risque, par exemple $\\hat r_{t+h} / \\hat\\sigma_{t+h}$, où $\\hat\\sigma_{t+h}$ est une prévision de volatilité.\n",
    "\n",
    "4. Évaluation mieux adaptée via des métriques de ranking et de portefeuille. En pratique, l’utilité d’un modèle de rendements est souvent mieux reflétée par :\n",
    "- des mesures de corrélation de rang (par exemple corrélation de Spearman) entre $\\hat r_{t+h}$ et $r_{t+h}$,\n",
    "- la performance d’un portefeuille construit à partir des scores (exemple : long sur le top quantile et short sur le bottom quantile),\n",
    "- des statistiques de risque (volatilité, drawdown) et de turnover.\n",
    "Ces critères sont souvent plus informatifs que l’accuracy binaire lorsque le signal est faible mais économiquement exploitable.\n",
    "\n",
    "### 4) Remarque : la régression ne garantit pas un $R^2$ élevé\n",
    "Prédire des rendements reste difficile et l’on observe fréquemment des $R^2$ faibles hors-échantillon. Cependant, un $R^2$ faible n’exclut pas une utilité économique si le modèle améliore le classement relatif des actifs ou la prise de décision sur les extrêmes, ce qui est souvent l’objectif opérationnel.\n",
    "\n",
    "### Conclusion\n",
    "Une accuracy proche de 51 % sur la prédiction du signe du rendement suggère que, dans cette formulation, le problème est dominé par le bruit et que le seuil $r_{t+h}>0$ est peu informatif et possiblement mal aligné avec l’objectif économique. Reformuler la tâche en régression (prédire la valeur du rendement) ou, plus généralement, en problème de scoring/ranking permet de conserver l’information de magnitude, de définir des règles de décision plus robustes (quantiles, seuils tenant compte des coûts) et d’évaluer les modèles selon des critères plus cohérents avec la construction d’un portefeuille.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
