{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f105da5-3c3e-4d8d-8542-b645409ff616",
   "metadata": {},
   "source": [
    "### Prédiction de la valeur des rendements\n",
    "\n",
    "Dans une seconde approche, nous cherchons à prédire directement la valeur du rendement futur, ce qui conduit naturellement à formuler le problème comme un problème de régression. Contrairement à la classification directionnelle, l’objectif ici est d’estimer l’amplitude du rendement, et non seulement son signe.\n",
    "\n",
    "Cette formulation est plus exigeante, mais aussi plus informative d’un point de vue économique. Prédire la valeur du rendement permet, en principe, de construire des stratégies plus fines, telles que des allocations proportionnelles aux rendements attendus, des classements cross-sectionnels des actifs, ou encore des stratégies long/short pondérées par l’intensité du signal.\n",
    "\n",
    "Cependant, il est crucial de souligner que la prédiction de la valeur des rendements constitue un problème intrinsèquement complexe, en raison de la nature même des marchés financiers et de l’information dont nous disposons. Les rendements dépendent d’une multitude de facteurs exogènes, souvent imprévisibles et en grande partie absents de notre jeu de données : événements géopolitiques, décisions de politique monétaire, annonces macroéconomiques inattendues, chocs météorologiques affectant certaines industries, évolutions réglementaires, ou encore dynamiques comportementales des investisseurs. Une part substantielle des variations de prix est ainsi liée à de l’information nouvelle, par définition non observable au moment de la prédiction.\n",
    "\n",
    "De plus, même parmi les facteurs observables, notre dataset ne capture qu’un sous-ensemble très restreint de l’information pertinente. Les variables utilisées (prix passés, volumes, indicateurs techniques) ne reflètent qu’indirectement l’ensemble des anticipations, contraintes et stratégies d’une population d’agents hétérogènes. Les marchés agrègent en permanence ces informations dispersées, ce qui rend les relations entre variables explicatives et rendements futurs à la fois faibles, non linéaires et instables dans le temps.\n",
    "\n",
    "Dans ce contexte, il est important de souligner que même une capacité prédictive extrêmement limitée constitue déjà une prouesse. Lorsqu’un modèle parvient à extraire un signal, aussi faible soit-il, dans un environnement dominé par l’incertitude et l’information non observable, cela signifie qu’il capte une régularité exploitable au-delà du bruit. En finance, une amélioration marginale de la prévision — même de très faible amplitude — peut suffire à générer une espérance de gain positive lorsqu’elle est correctement exploitée, par exemple via des stratégies long/short, des classements relatifs ou des agrégations de signaux à grande échelle. De telles stratégies, lorsqu’elles sont robustes et appliquées de manière systématique, peuvent produire des performances économiquement significatives et représenter une source de valeur substantielle, malgré des métriques statistiques (comme le R²) apparemment modestes.\n",
    "\n",
    "C’est néanmoins cette formulation qui est la plus couramment adoptée dans la littérature empirique récente sur la prédiction des rendements, notamment dans les travaux utilisant des méthodes de machine learning. Des articles de référence, comme Gu, Kelly & Xiu (2020), évaluent explicitement la capacité des modèles à prédire les rendements excédentaires en niveau et utilisent des métriques telles que la MSE ou le R² hors-échantillon pour quantifier le pouvoir prédictif.\n",
    "\n",
    "Cette seconde tentative vise donc à répondre à la question : dans quelle mesure les variables considérées permettent-elles de prédire l’intensité des rendements futurs, au-delà de leur simple direction, et comment ce pouvoir prédictif — nécessairement limité — se compare-t-il aux ordres de grandeur observés dans la littérature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "e8a30e6d-8da4-4a64-9b61-678252301cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "5b16b147-59ce-41bd-8d29-170bc45fc98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>MMM</td>\n",
       "      <td>37.356306</td>\n",
       "      <td>37.915495</td>\n",
       "      <td>37.301752</td>\n",
       "      <td>37.460873</td>\n",
       "      <td>3817632.0</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-01-04</td>\n",
       "      <td>MMM</td>\n",
       "      <td>37.460883</td>\n",
       "      <td>37.742749</td>\n",
       "      <td>37.129005</td>\n",
       "      <td>37.156284</td>\n",
       "      <td>4358942.0</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-01-05</td>\n",
       "      <td>MMM</td>\n",
       "      <td>37.142662</td>\n",
       "      <td>37.256318</td>\n",
       "      <td>36.701679</td>\n",
       "      <td>36.701679</td>\n",
       "      <td>3462779.0</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-01-06</td>\n",
       "      <td>MMM</td>\n",
       "      <td>36.769829</td>\n",
       "      <td>37.460855</td>\n",
       "      <td>36.742550</td>\n",
       "      <td>37.033508</td>\n",
       "      <td>3605342.0</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-01-07</td>\n",
       "      <td>MMM</td>\n",
       "      <td>37.051714</td>\n",
       "      <td>37.642720</td>\n",
       "      <td>36.938058</td>\n",
       "      <td>37.415409</td>\n",
       "      <td>3938428.0</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Ticker       Open       High        Low      Close     Volume  \\\n",
       "0  2005-01-03    MMM  37.356306  37.915495  37.301752  37.460873  3817632.0   \n",
       "1  2005-01-04    MMM  37.460883  37.742749  37.129005  37.156284  4358942.0   \n",
       "2  2005-01-05    MMM  37.142662  37.256318  36.701679  36.701679  3462779.0   \n",
       "3  2005-01-06    MMM  36.769829  37.460855  36.742550  37.033508  3605342.0   \n",
       "4  2005-01-07    MMM  37.051714  37.642720  36.938058  37.415409  3938428.0   \n",
       "\n",
       "        Sector  \n",
       "0  Industrials  \n",
       "1  Industrials  \n",
       "2  Industrials  \n",
       "3  Industrials  \n",
       "4  Industrials  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../sp500_ohlcv_2005_2025_2.csv\")\n",
    "sp500 = pd.read_csv(\"../sectors.csv\")\n",
    "\n",
    "df = df.merge(\n",
    "    sp500[['Ticker', 'Sector']], \n",
    "    on='Ticker', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "0e217090-6036-40f2-a7de-4d66e8c7950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Suppose df a les colonnes : Date, Ticker, Open, High, Low, Close, Volume\n",
    "df = df.sort_values([\"Ticker\", \"Date\"])\n",
    "\n",
    "# --- 1) Log-return\n",
    "df[\"log_return\"] = np.log(df[\"Close\"]) - np.log(df[\"Close\"].shift(1))\n",
    "\n",
    "# --- 2) Target = log-return de demain (r_{t+1})\n",
    "df[\"target\"] = df.groupby(\"Ticker\")[\"log_return\"].shift(-1)\n",
    "\n",
    "# --- 3) Features momentum\n",
    "df[\"mom_5\"]  = df.groupby(\"Ticker\")[\"Close\"].transform(lambda x: x / x.shift(5) - 1)\n",
    "df[\"mom_21\"] = df.groupby(\"Ticker\")[\"Close\"].transform(lambda x: x / x.shift(21) - 1)\n",
    "\n",
    "# --- 4) Features volatilité\n",
    "df[\"vol_5\"]  = df.groupby(\"Ticker\")[\"log_return\"].transform(lambda x: x.rolling(5).std())\n",
    "df[\"vol_21\"] = df.groupby(\"Ticker\")[\"log_return\"].transform(lambda x: x.rolling(21).std())\n",
    "\n",
    "# --- 5) High–Low range\n",
    "df[\"range\"] = (df[\"High\"] - df[\"Low\"]) / df[\"Open\"]\n",
    "\n",
    "# --- 6) Volume z-score\n",
    "df[\"volume_z\"] = df.groupby(\"Ticker\")[\"Volume\"].transform(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "\n",
    "df['Return'] = df.groupby('Ticker')['Close'].pct_change(fill_method=None)\n",
    "\n",
    "# --- 7) Clean\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "1534f414-3b5e-44c2-b28a-d09dc5b9d9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "def regression(df, features):\n",
    "    \"\"\"\n",
    "    Entraîne une régression linéaire sur un sous-échantillon temporel (2010–2021),\n",
    "    avec un split train/val/test réalisé *par dates* (toutes les lignes d'une même\n",
    "    date vont dans le même split), puis évalue sur le test et calcule un RMSE par secteur.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Doit contenir au minimum : \"Date\", \"target\", \"Sector\" + les colonnes de `features`.\n",
    "        Chaque ligne correspond typiquement à (Date, action) avec des features associées.\n",
    "    features : list[str]\n",
    "        Liste des noms de colonnes à utiliser comme variables explicatives.\n",
    "\n",
    "    Retours\n",
    "    -------\n",
    "    model : LinearRegression\n",
    "        Modèle sklearn entraîné.\n",
    "    sector_rmse : pd.Series\n",
    "        RMSE par secteur (index = secteurs), trié du meilleur au pire.\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------\n",
    "    # 1) Restriction temporelle\n",
    "    # -------------------------\n",
    "    # On garde uniquement les observations entre 2010-01-01 et 2021-12-31 (inclus).\n",
    "    # NB : si df[\"Date\"] est déjà un datetime, c'est parfait. Sinon, la comparaison\n",
    "    # de chaînes peut produire des effets inattendus → à convertir en amont idéalement.\n",
    "    mask = (df[\"Date\"] >= \"2010-01-01\") & (df[\"Date\"] <= \"2021-12-31\")\n",
    "    df_period = df.loc[mask].copy()\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # 2) Split train/val/test (par *dates*)\n",
    "    # ---------------------------------------\n",
    "    # Objectif : éviter de mettre la même date à la fois dans train et test.\n",
    "    # On récupère la liste des dates uniques, puis on la mélange aléatoirement.\n",
    "    unique_dates = df_period[\"Date\"].unique()\n",
    "\n",
    "    rng = np.random.default_rng(seed=42)  # seed fixé → résultats reproductibles\n",
    "    rng.shuffle(unique_dates)             # mélange des dates (attention: non chronologique)\n",
    "\n",
    "    # Proportions : 60% train, 20% val, 20% test (approx).\n",
    "    n_dates = len(unique_dates)\n",
    "    n_train = int(0.6 * n_dates)\n",
    "    n_val   = int(0.2 * n_dates)\n",
    "    # le reste est attribué au test\n",
    "\n",
    "    train_dates = unique_dates[:n_train]\n",
    "    val_dates   = unique_dates[n_train:n_train + n_val]\n",
    "    test_dates  = unique_dates[n_train + n_val:]\n",
    "\n",
    "    # On sélectionne les lignes correspondant aux dates de chaque split\n",
    "    train = df_period[df_period[\"Date\"].isin(train_dates)]\n",
    "    val   = df_period[df_period[\"Date\"].isin(val_dates)]\n",
    "    test  = df_period[df_period[\"Date\"].isin(test_dates)].copy()  # copy car on ajoute une colonne ensuite\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # 3) Préparation des matrices X / y\n",
    "    # ---------------------------------------\n",
    "    X_train, y_train = train[features], train[\"target\"]\n",
    "    X_val, y_val     = val[features],   val[\"target\"]   # actuellement non utilisé (mais prêt pour tuning)\n",
    "    X_test, y_test   = test[features],  test[\"target\"]\n",
    "\n",
    "    # -------------------------\n",
    "    # 4) Entraînement du modèle\n",
    "    # -------------------------\n",
    "    # LinearRegression = OLS (avec intercept) sans régularisation.\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # -------------------------\n",
    "    # 5) Prédiction et métriques\n",
    "    # -------------------------\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Métriques globales de régression\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae  = mean_absolute_error(y_test, y_pred)\n",
    "    r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Variance de la cible sur le test (utile pour comparer l'échelle des erreurs)\n",
    "    var_test = np.var(y_test)\n",
    "\n",
    "    print(\"RMSE :\", rmse)\n",
    "    print(\"MAE  :\", mae)\n",
    "    print(\"R²   :\", r2)\n",
    "    print(\"Var(y_test) :\", var_test)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # 6) RMSE par secteur (diagnostic)\n",
    "    # ---------------------------------------\n",
    "    # On ajoute la prédiction au DataFrame de test\n",
    "    test[\"pred\"] = y_pred\n",
    "\n",
    "    # Pour chaque secteur, on calcule le RMSE sur les lignes de ce secteur\n",
    "    sector_rmse = (\n",
    "        test.groupby(\"Sector\")\n",
    "            .apply(\n",
    "                lambda g: np.sqrt(mean_squared_error(g[\"target\"], g[\"pred\"])),\n",
    "                include_groups=False\n",
    "            )\n",
    "            .sort_values()\n",
    "    )\n",
    "\n",
    "    return model, sector_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "a65f8f76-f9c7-4ad6-b1ee-40e0f2dd34c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.020804340409584315\n",
      "MAE  : 0.012958511181494624\n",
      "R²   : -0.007582188713726623\n",
      "Var(y_test) : 0.0004295635479924462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LinearRegression(),\n",
       " Sector\n",
       " Consumer Staples          0.015680\n",
       " Utilities                 0.016088\n",
       " Real Estate               0.019053\n",
       " Health Care               0.019305\n",
       " Financials                0.019404\n",
       " Industrials               0.020485\n",
       " Materials                 0.021868\n",
       " Information Technology    0.023075\n",
       " Communication Services    0.023257\n",
       " Consumer Discretionary    0.023942\n",
       " Energy                    0.027032\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression(df, [\"mom_5\", \"mom_21\", \"vol_5\", \"vol_21\", \"range\", \"volume_z\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a8a0ef-ba80-4f13-b16f-ccdbeebc7cf8",
   "metadata": {},
   "source": [
    "### Interprétation des résultats du modèle de régression linéaire\n",
    "\n",
    "Le modèle de régression linéaire appliqué à notre cible produit les performances suivantes :\n",
    "\n",
    "- RMSE : 0.02078  \n",
    "- MAE : 0.01294  \n",
    "- R² : –0.0076\n",
    "\n",
    "Plusieurs éléments se dégagent immédiatement :\n",
    "\n",
    "1. Le R² négatif indique que la régression linéaire fait moins bien qu’un modèle trivial qui prédirait simplement la moyenne historique de la variable cible. Autrement dit, la variance expliquée est nulle, voire légèrement détériorée.\n",
    "\n",
    "2. Le RMSE et le MAE sont proches de la dispersion naturelle du rendement à prédire, ce qui montre que le modèle n’arrive pas à extraire un signal utile à partir des caractéristiques disponibles.\n",
    "\n",
    "3. Ce résultat est cohérent avec la littérature : les rendements financiers sont notoirement difficiles à modéliser de manière linéaire, en raison de relations potentiellement non linéaires, interactives, et faiblement signalées.\n",
    "\n",
    "Ces observations suggèrent que la régression linéaire est trop restrictive pour capturer les relations complexes entre les variables explicatives et les rendements futurs.  \n",
    "Pour cette raison, nous passons à un modèle plus flexible — XGBoost — qui permet de modéliser des non-linéarités, des interactions entre features et une structure plus riche. Nous espérons ainsi obtenir une amélioration significative en termes d’erreur de prédiction et de R² hors-échantillon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "3af3abb7-7667-4af9-af0d-358c93eec364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "def regression_xgb(df, features):\n",
    "    \"\"\"\n",
    "    Entraîne un modèle XGBoost de régression (XGBRegressor) pour prédire `target`\n",
    "    à partir de `features`, avec un split temporel :\n",
    "\n",
    "      - train : dates < 2018-01-01\n",
    "      - val   : 2018-01-01 <= dates < 2021-01-01\n",
    "      - test  : dates >= 2021-01-01\n",
    "\n",
    "    On utilise `val` pour l'early stopping, puis on évalue sur `test`.\n",
    "    Enfin, on calcule une métrique par secteur.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Doit contenir : \"Date\", \"target\", \"Sector\" + les colonnes de `features`.\n",
    "    features : list[str]\n",
    "        Colonnes utilisées comme variables explicatives.\n",
    "\n",
    "    Retours\n",
    "    -------\n",
    "    sector_metric : pd.Series\n",
    "        Série indexée par \"Sector\", triée par valeur croissante.\n",
    "    \"\"\"\n",
    "\n",
    "    # Copie défensive pour éviter de modifier le df original\n",
    "    df = df.copy()\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 1) Split train/val/test (chronologique)\n",
    "    # ----------------------------------------\n",
    "    # Objectif : mimer un vrai cadre out-of-sample (train sur le passé, test sur le futur).\n",
    "    train = df[df[\"Date\"] < \"2018-01-01\"]\n",
    "    val   = df[(df[\"Date\"] >= \"2018-01-01\") & (df[\"Date\"] < \"2021-01-01\")]\n",
    "    test  = df[df[\"Date\"] >= \"2021-01-01\"].copy()  # copy car on ajoute ensuite une colonne \"pred\"\n",
    "\n",
    "    X_train, y_train = train[features], train[\"target\"]\n",
    "    X_val,   y_val   = val[features],   val[\"target\"]\n",
    "    X_test,  y_test  = test[features],  test[\"target\"]\n",
    "\n",
    "    # -------------------------\n",
    "    # 2) Modèle XGBoost\n",
    "    # -------------------------\n",
    "    # Hyperparamètres \"raisonnables\" pour un baseline :\n",
    "    # - n_estimators : nombre max d'arbres (l'early stopping peut arrêter avant)\n",
    "    # - max_depth    : complexité de chaque arbre\n",
    "    # - learning_rate: shrinkage (plus petit = plus stable mais nécessite + d'arbres)\n",
    "    # - subsample / colsample_bytree : bagging de lignes/colonnes (régularisation)\n",
    "    # - objective    : perte de régression MSE\n",
    "    # - early_stopping_rounds : stop si la perf sur `val` n'améliore plus pendant 30 itérations\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=\"reg:squarederror\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        early_stopping_rounds=30,\n",
    "    )\n",
    "\n",
    "    # -------------------------\n",
    "    # 3) Entraînement + early stopping\n",
    "    # -------------------------\n",
    "    # eval_set : on fournit la validation pour surveiller la perf.\n",
    "    # verbose=False : silence pendant l'entraînement.\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # -------------------------\n",
    "    # 4) Prédiction sur le test\n",
    "    # -------------------------\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # -------------------------\n",
    "    # 5) Métriques globales (test)\n",
    "    # -------------------------\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae  = mean_absolute_error(y_test, y_pred)\n",
    "    r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(\"RMSE :\", rmse)\n",
    "    print(\"MAE  :\", mae)\n",
    "    print(\"R²   :\", r2)\n",
    "\n",
    "    # On stocke les prédictions pour pouvoir grouper et diagnostiquer\n",
    "    test[\"pred\"] = y_pred\n",
    "\n",
    "    # -------------------------\n",
    "    # 6) Métrique par secteur\n",
    "    sector_r2 = (\n",
    "        test.groupby(\"Sector\")\n",
    "            .apply(lambda g: r2_score(g[\"target\"], g[\"pred\"]), include_groups=False)\n",
    "            .sort_values()\n",
    "    )\n",
    "\n",
    "    return sector_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "1362b2b1-cbdc-41cf-ae4d-c26098b1b410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.02018808612331705\n",
      "MAE  : 0.013768098419402148\n",
      "R²   : 4.016453471267223e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sector\n",
       "Consumer Staples         -0.000668\n",
       "Energy                   -0.000592\n",
       "Health Care              -0.000386\n",
       "Communication Services   -0.000157\n",
       "Materials                -0.000060\n",
       "Utilities                -0.000014\n",
       "Real Estate               0.000008\n",
       "Consumer Discretionary    0.000040\n",
       "Industrials               0.000047\n",
       "Financials                0.000058\n",
       "Information Technology    0.000125\n",
       "dtype: float64"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_xgb(df, [\"Open\", \"Close\", \"High\", \"Low\", \"mom_5\", \"mom_21\", \"vol_5\", \"vol_21\", \"range\", \"volume_z\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0873406-4697-42b7-9d6f-361e07ee809b",
   "metadata": {},
   "source": [
    "### Limites du découpage temporel strict et motivation d’une méthodologie alternative\n",
    "\n",
    "Dans un premier temps, nous avons évalué le modèle selon un protocole standard en finance empirique, en l’entraînant sur une première plage temporelle (données antérieures à 2018) et en l’évaluant hors-échantillon sur une période ultérieure (données postérieures à 2018). Ce découpage, conforme à la logique de prévision du futur à partir du passé, vise à reproduire les conditions réelles d'utilisation d'un tel modèle par un fond d'investissement. Toutefois, dans ce cadre, le modèle obtient un R² hors-échantillon quasiement nul, indiquant qu’il ne parvient pas à améliorer la prédiction par rapport à une simple constante (la moyenne de la cible).\n",
    "\n",
    "Ce résultat suggère que, sur un bloc temporel futur strictement séparé, les relations estimées dans le passé ne sont pas suffisamment stables pour fournir un pouvoir prédictif exploitable. Cela peut s’expliquer par plusieurs facteurs : changements de régime de marché, instabilité des relations entre caractéristiques et rendements, ou encore un rapport signal-bruit particulièrement faible à court horizon.\n",
    "\n",
    "Afin d’aller au-delà de ce constat et d’évaluer si les variables considérées contiennent néanmoins un signal prédictif exploitable d’un point de vue statistique, nous adoptons alors une méthodologie alternative. L’idée est de répartir plus équitablement les dates de l’ensemble de l’échantillon entre les jeux d’entraînement, de validation et de test, plutôt que de concentrer le test sur un seul bloc temporel terminal. Cette approche se rapproche davantage d’un cadre de prédiction i.i.d., permettant de mieux mesurer la capacité intrinsèque du modèle à capturer une relation entre caractéristiques et rendements.\n",
    "\n",
    "Toutefois, une telle répartition des dates sur l’ensemble de la période soulève immédiatement un risque majeur de fuite d’information (data leakage) : dans la mesure où la cible est le rendement futur, on pourrait trouver une date dans l'échantillon d'entrainement qui serait une date target dans l'échantillon de test, ie une date pour laquelle on souhaite prédire les rendements (rendements déjà rencontrés dans l'échantillon d'entrainement). Pour pallier ce problème, nous imposons une contrainte supplémentaire : les dates conservées dans tout le dataset doivent être espacées d’au moins 1 périodes, de sorte qu’aucune observation ne puisse apparaître simultanément comme donnée explicative et comme composante de la cible d’une autre observation. Ce sous-échantillonnage temporel permet ainsi de répartir les dates sur l’ensemble du dataset tout en préservant l’indépendance effective entre observations et en évitant toute utilisation implicite d’informations futures.\n",
    "\n",
    "Cette méthodologie ne vise pas à reproduire fidèlement un cadre de production pour un fonds d’investissement, mais à répondre à une question complémentaire : existe-t-il, indépendamment des contraintes temporelles strictes, un signal prédictif mesurable dans les données lorsque l’on contrôle soigneusement les risques de data leakage ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "4b7c1eec-19c5-4416-a788-0675c493e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "def xgb(df, features, H):\n",
    "    \"\"\"\n",
    "    Pipeline XGBoost pour prédire une cible \"forward\" sur horizon H :\n",
    "\n",
    "    - target(t, i) = moyenne des log_return de l'actif i sur les H prochains jours\n",
    "                     (rolling(H).mean().shift(-H))\n",
    "      => la target utilise des infos futures, donc on doit être très prudent sur le split.\n",
    "\n",
    "    - target_date = date du dernier jour utilisé pour construire la target (t+H)\n",
    "      (utile pour raisonner sur l'horizon, même si ici on split sur df[\"Date\"]).\n",
    "\n",
    "    Ensuite :\n",
    "    - restriction à 2010–2021\n",
    "    - split train/val/test par dates *chronologiques*\n",
    "    - \"thinning\" des dates utilisées : on ne garde qu'une date toutes les (H+1) dates\n",
    "      pour réduire l'overlap de fenêtres et limiter le leak mécanique lié au fait que\n",
    "      des targets consécutives partagent une partie du futur.\n",
    "\n",
    "    Enfin :\n",
    "    - entraînement XGBRegressor avec early stopping sur val\n",
    "    - évaluation sur test (RMSE/MAE/R² + Var(y_test))\n",
    "    - métrique par secteur (attention : dans le code original c'est du R² par secteur)\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Doit contenir : \"Date\", \"Ticker\", \"Sector\", \"log_return\" + features.\n",
    "        Une ligne ~ (Date, Ticker).\n",
    "    features : list[str]\n",
    "        Colonnes explicatives.\n",
    "    H : int\n",
    "        Horizon en jours (nombre de jours futurs utilisés pour la target).\n",
    "\n",
    "    Retours\n",
    "    -------\n",
    "    sector_r2 : pd.Series\n",
    "        R² par secteur (trié).\n",
    "    test_r2 : float\n",
    "        R² global sur le test.\n",
    "    \"\"\"\n",
    "\n",
    "    # Copie défensive pour ne pas modifier le df original\n",
    "    df = df.copy()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 1) Construction de la target forward (horizon H)\n",
    "    # ---------------------------------------------------------\n",
    "    # Pour chaque Ticker, on calcule la moyenne glissante sur H jours,\n",
    "    # puis on la décale de -H pour que la valeur soit alignée sur la date t\n",
    "    # (target à la date t = moyenne des returns sur [t, ..., t+H-1] selon l'indexation).\n",
    "    df[\"target\"] = (\n",
    "        df.groupby(\"Ticker\")[\"log_return\"]\n",
    "          .transform(lambda s: s.rolling(H).mean().shift(-H))\n",
    "    )\n",
    "\n",
    "    # Date associée à la réalisation de la target (dernier jour utilisé) ~ t+H\n",
    "    df[\"target_date\"] = df.groupby(\"Ticker\")[\"Date\"].shift(-H)\n",
    "\n",
    "    # Suppression des bords de série (où le futur manque => target NaN)\n",
    "    df = df.dropna(subset=[\"target\", \"target_date\"])\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2) Restriction temporelle globale\n",
    "    # ---------------------------------------------------------\n",
    "    mask = (df[\"Date\"] >= \"2010-01-01\") & (df[\"Date\"] <= \"2021-12-31\")\n",
    "    df_period = df.loc[mask].copy()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3) Choix des dates utilisées : thinning pour limiter overlap\n",
    "    # ---------------------------------------------------------\n",
    "    # On récupère toutes les dates disponibles (triées).\n",
    "    # Puis on ne garde qu'une date toutes les (H+1) dates.\n",
    "    # Intuition : deux dates t et t+1 ont des targets très corrélées car elles partagent\n",
    "    # beaucoup de jours futurs dans la moyenne; ça peut rendre l'évaluation trop optimiste\n",
    "    # si train/test contiennent des dates proches.\n",
    "    all_dates = np.sort(df_period[\"Date\"].unique())\n",
    "    used_dates = all_dates[:: (H + 1)]\n",
    "\n",
    "    # Split 60/20/20 sur ces dates \"décimées\", en respectant l'ordre chronologique\n",
    "    n = len(used_dates)\n",
    "    i1 = int(0.6 * n)\n",
    "    i2 = int(0.8 * n)\n",
    "\n",
    "    train_dates = used_dates[:i1]\n",
    "    val_dates   = used_dates[i1:i2]\n",
    "    test_dates  = used_dates[i2:]\n",
    "\n",
    "    # On forme les ensembles : toutes les lignes dont la Date appartient à chaque bloc\n",
    "    train = df_period[df_period[\"Date\"].isin(train_dates)]\n",
    "    val   = df_period[df_period[\"Date\"].isin(val_dates)]\n",
    "    test  = df_period[df_period[\"Date\"].isin(test_dates)].copy()\n",
    "\n",
    "    X_train, y_train = train[features], train[\"target\"]\n",
    "    X_val,   y_val   = val[features],   val[\"target\"]\n",
    "    X_test,  y_test  = test[features],  test[\"target\"]\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 4) Modèle XGBoost + early stopping\n",
    "    # ---------------------------------------------------------\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=\"reg:squarederror\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        early_stopping_rounds=30,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 5) Prédictions et métriques globales\n",
    "    # ---------------------------------------------------------\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae  = mean_absolute_error(y_test, y_pred)\n",
    "    test_r2 = r2_score(y_test, y_pred)\n",
    "    var_test = np.var(y_test)\n",
    "\n",
    "    print(\"RMSE :\", rmse)\n",
    "    print(\"MAE  :\", mae)\n",
    "    print(\"R²   :\", test_r2)\n",
    "    print(\"Var(y_test) :\", var_test)\n",
    "\n",
    "    # Stockage pour diagnostic par groupe\n",
    "    test[\"pred\"] = y_pred\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 6) Métrique par secteur\n",
    "    # ---------------------------------------------------------\n",
    "    sector_r2 = (\n",
    "        test.groupby(\"Sector\")\n",
    "            .apply(lambda g: r2_score(g[\"target\"], g[\"pred\"]), include_groups=False)\n",
    "            .sort_values()\n",
    "    )\n",
    "\n",
    "    return sector_r2, test_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "af2bc50c-c512-4a07-970f-ae3f9a1ec896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.025317301950024348\n",
      "MAE  : 0.016169723488936045\n",
      "R²   : -1.7216072269121696e-05\n",
      "Var(y_test) : 0.0006409547433055247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Sector\n",
       " Energy                   -0.001586\n",
       " Financials               -0.000844\n",
       " Information Technology   -0.000673\n",
       " Health Care              -0.000663\n",
       " Consumer Discretionary   -0.000593\n",
       " Industrials              -0.000561\n",
       " Materials                -0.000412\n",
       " Real Estate               0.000276\n",
       " Utilities                 0.001741\n",
       " Communication Services    0.002190\n",
       " Consumer Staples          0.004514\n",
       " dtype: float64,\n",
       " -1.7216072269121696e-05)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb(df, [\"Open\", \"Close\", \"High\", \"Low\", \"mom_5\", \"mom_21\", \"vol_5\", \"vol_21\", \"range\", \"volume_z\"], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01caf026-1571-4b23-ac97-a0c28061f549",
   "metadata": {},
   "source": [
    "Essayons désormais de prédire non plus le rendement à un jour, mais la **moyenne des rendements futurs sur un horizon \\(H > 1\\)**. Ce changement de cible est motivé par plusieurs considérations à la fois statistiques et économiques.\n",
    "\n",
    "D’un point de vue statistique, les rendements à très court terme sont fortement dominés par du bruit microstructurel, ce qui limite fortement la capacité prédictive des modèles, même flexibles. En considérant une moyenne de rendements sur plusieurs jours, on procède à une agrégation temporelle qui permet de réduire la variance du bruit et d’améliorer le rapport signal–bruit de la variable cible.\n",
    "\n",
    "D’un point de vue économique, de nombreux mécanismes plausibles (momentum à court et moyen terme, diffusion progressive de l’information, ajustements sectoriels ou macroéconomiques) s’expriment à des horizons de quelques jours à quelques semaines plutôt qu’à l’échelle journalière. Prédire une moyenne de rendements sur un horizon \\(H > 1\\) permet donc de mieux capter ces dynamiques sous-jacentes.\n",
    "\n",
    "Enfin, cette approche est également cohérente avec la littérature empirique, qui montre que la prédictibilité des rendements est souvent plus élevée à des horizons intermédiaires qu’à l’horizon journalier, tandis qu’elle tend à se dégrader à des horizons trop longs. Nous espérons ainsi que le passage à des horizons \\(H > 1\\) conduira à des performances de prédiction améliorées, mesurées notamment par une baisse des erreurs de prédiction et une augmentation du R² hors-échantillon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "bffaf80a-cc48-4dcc-b46c-284395d05ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.012168327089261848\n",
      "MAE  : 0.007607085605767072\n",
      "R²   : 0.0033383739622092623\n",
      "Var(y_test) : 0.00014856414683076137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Sector\n",
       " Energy                   -0.017291\n",
       " Consumer Staples         -0.009473\n",
       " Utilities                -0.002552\n",
       " Communication Services   -0.001907\n",
       " Real Estate               0.001525\n",
       " Materials                 0.003810\n",
       " Health Care               0.003963\n",
       " Financials                0.004684\n",
       " Industrials               0.005460\n",
       " Consumer Discretionary    0.010127\n",
       " Information Technology    0.011696\n",
       " dtype: float64,\n",
       " 0.0033383739622092623)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb(df, [\"Open\", \"Close\", \"High\", \"Low\", \"mom_5\", \"mom_21\", \"vol_5\", \"vol_21\", \"range\", \"volume_z\"], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "272a6915-cbec-4958-af4b-4d57b8066ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.005167912558057384\n",
      "MAE  : 0.0033930680111847523\n",
      "R²   : 0.0028771991372952277\n",
      "Var(y_test) : 2.678438421488326e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Sector\n",
       " Real Estate              -0.006824\n",
       " Information Technology   -0.005574\n",
       " Health Care              -0.005050\n",
       " Consumer Staples         -0.003562\n",
       " Consumer Discretionary   -0.001459\n",
       " Materials                 0.000620\n",
       " Financials                0.003247\n",
       " Industrials               0.004053\n",
       " Utilities                 0.006082\n",
       " Communication Services    0.007454\n",
       " Energy                    0.009502\n",
       " dtype: float64,\n",
       " 0.0028771991372952277)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb(df, [ \"Close\", \"Low\", \"High\", \"Open\", \"mom_5\", \"mom_21\", \"vol_5\", \"vol_21\", \"range\", \"volume_z\"], 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "b0aedae2-246b-4709-ab81-584b61e1b53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.003255322651162046\n",
      "MAE  : 0.002304830580333548\n",
      "R²   : 0.0026715189053980737\n",
      "Var(y_test) : 1.0625511818872341e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Sector\n",
       " Utilities                -0.060184\n",
       " Information Technology   -0.013179\n",
       " Real Estate              -0.002790\n",
       " Health Care              -0.002003\n",
       " Materials                -0.000782\n",
       " Consumer Discretionary    0.001195\n",
       " Financials                0.001757\n",
       " Industrials               0.002952\n",
       " Consumer Staples          0.003434\n",
       " Energy                    0.004256\n",
       " Communication Services    0.004262\n",
       " dtype: float64,\n",
       " 0.0026715189053980737)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb(df, [ \"Close\", \"Low\", \"High\", \"Open\", \"mom_5\", \"mom_21\", \"vol_5\", \"vol_21\", \"range\", \"volume_z\"], 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eda1af-3893-4a57-b308-d93b04947259",
   "metadata": {},
   "source": [
    "### Interprétation des performances par secteur et selon l’horizon \\(H\\)\n",
    "\n",
    "Les tableaux ci-dessus présentent les performances du modèle (mesurées par le R² hors-échantillon) par secteur pour différents horizons de prévision \\(H\\).\n",
    "\n",
    "Un premier constat général est que le R² augmente lorsque l’horizon de prévision passe de \\(H = 1\\) à \\(H = 5\\), puis à \\(H = 21\\). Cette évolution est cohérente avec la littérature sur la prévision des rendements financiers. À très court horizon (\\(H = 1\\)), les rendements sont largement dominés par du bruit microstructurel et idiosyncratique (bid–ask bounce, effets de liquidité, chocs transitoires), ce qui rend la prédiction extrêmement difficile. Ce point est bien documenté, notamment dans les travaux de Campbell, Lo et MacKinlay (1997) et de Hasbrouck (2007), qui montrent que la variance des rendements journaliers est en grande partie non prévisible.\n",
    "\n",
    "Lorsque l’horizon de prévision augmente, la cible correspond à une moyenne de rendements futurs, ce qui a pour effet de lisser le bruit de court terme et de faire émerger des composantes plus persistantes, telles que le momentum ou certaines expositions factorielles. De nombreux travaux empiriques montrent que ces effets sont plus visibles à des horizons de quelques semaines à quelques mois (Jegadeesh et Titman, 1993 ; Moskowitz, Ooi et Pedersen, 2012). Dans ce cadre, il est donc naturel d’observer une amélioration du R² lorsque l’on passe d’un horizon journalier à un horizon intermédiaire.\n",
    "\n",
    "Cette amélioration est particulièrement marquée pour des secteurs comme l’Information Technology, les Financials ou les Industrials, dont les rendements sont davantage liés à des dynamiques économiques ou financières de moyen terme, plutôt qu’à des fluctuations purement journalières.\n",
    "\n",
    "En revanche, lorsque l’horizon devient plus long (\\(H = 50\\)), le R² diminue à nouveau. À ces horizons, plusieurs phénomènes peuvent expliquer la dégradation des performances :\n",
    "- l’augmentation de \\(H\\) réduit mécaniquement le nombre d’observations effectives (H observations ignorées sur H+1 pour éviter dataleak), ce qui dégrade le rapport signal/bruit et la précision de l’estimation.\n",
    "- le lien entre les variables explicatives utilisées (principalement de court à moyen terme) et les rendements très futurs devient plus faible ;\n",
    "- les rendements à long horizon intègrent des chocs macroéconomiques, réglementaires ou géopolitiques difficilement capturables par les caractéristiques considérées ;\n",
    "\n",
    "Cette perte de pouvoir prédictif à long horizon est également soulignée dans la littérature sur la prévisibilité de la prime de risque actions (Goyal et Welch, 2008 ; Boudoukh et al., 2008), qui montre que la prévision devient instable et fortement dépendante de la période considérée.\n",
    "\n",
    "Ainsi, ces résultats suggèrent l’existence d’un horizon intermédiaire optimal (ici autour de quelques semaines) pour lequel le compromis entre réduction du bruit à court terme et perte d’information à long terme est le plus favorable. Ce comportement est conforme à ce que l’on observe classiquement dans la littérature sur la prévision des rendements, où les modèles ont tendance à mieux performer à des horizons intermédiaires qu’à des horizons très courts ou très longs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1723169-7744-4a14-aa31-583d8ef6b3df",
   "metadata": {},
   "source": [
    "Essayons d'améliorer ces résutlats un peu plus en spécialisant un modèlé en l'entrainant sur un seul Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "4fe8561b-b094-4cf4-8dff-8999511179d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_ticker(df, ticker, features, H):\n",
    "    \"\"\"\n",
    "    Wrapper autour de `xgb` pour entraîner/évaluer le modèle sur un seul Ticker.\n",
    "\n",
    "    Idée :\n",
    "    - On isole d'abord les lignes correspondant à `ticker`.\n",
    "    - On appelle ensuite la fonction `xgb` (qui construit la target forward, split,\n",
    "      entraîne XGBoost, calcule les métriques et renvoie les scores).\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame complet contenant plusieurs tickers.\n",
    "        Doit contenir au minimum : \"Ticker\", \"Date\", \"log_return\" + features\n",
    "        (et potentiellement \"Sector\" si `xgb` calcule des métriques par secteur).\n",
    "    ticker : str\n",
    "        Symbole de l'action à sélectionner (ex: \"AAPL\").\n",
    "    features : list[str]\n",
    "        Colonnes explicatives à utiliser.\n",
    "    H : int\n",
    "        Horizon en jours pour la définition de la target (moyenne des log_return futurs).\n",
    "\n",
    "    Retour\n",
    "    ------\n",
    "    Même sortie que `xgb(df_sec, features, H)`.\n",
    "\n",
    "    Remarque importante :\n",
    "    - Si `xgb` calcule une métrique \"par secteur\" via groupby(\"Sector\"),\n",
    "      alors sur un seul ticker :\n",
    "        * soit tu as exactement 1 seul secteur => la \"série par secteur\" n'a qu'une valeur,\n",
    "        * soit la colonne \"Sector\" n'existe pas / est vide => ça plantera.\n",
    "      Dans ce cas, il vaut mieux adapter `xgb` pour proposer un mode \"ticker-only\"\n",
    "      (par ex. retourner plutôt des métriques globales + éventuellement par date).\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Filtrage sur le ticker demandé\n",
    "    # .copy() pour éviter SettingWithCopyWarning et toute modification du df original\n",
    "    df_ticker = df[df[\"Ticker\"] == ticker].copy()\n",
    "\n",
    "    # 2) Appel du pipeline principal sur ce sous-ensemble\n",
    "    return xgb(df_ticker, features, H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "ae834c8a-9716-4376-8a38-83718321d2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.017018133230228067\n",
      "MAE  : 0.0115406296138189\n",
      "R²   : 0.020610443492290464\n",
      "Var(y_test) : 0.00029571160598700243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Sector\n",
       " Consumer Discretionary    0.02061\n",
       " dtype: float64,\n",
       " 0.020610443492290464)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_ticker(df, \"HD\", [ \"Close\", \"Low\", \"High\", \"Open\", \"mom_5\", \"mom_21\", \"vol_5\", \"vol_21\", \"range\", \"volume_z\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "85c8f421-e418-46a0-af9f-7ed653ffa119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.01889231518191559\n",
      "MAE  : 0.013517061599754262\n",
      "R²   : 0.022540170870683718\n",
      "Var(y_test) : 0.00036515011900874585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Sector\n",
       " Information Technology    0.02254\n",
       " dtype: float64,\n",
       " 0.022540170870683718)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_ticker(df, \"AAPL\", [ \"Close\", \"Low\", \"High\", \"Open\", \"mom_5\", \"mom_21\", \"vol_5\", \"vol_21\", \"range\", \"volume_z\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "0842f1c4-61e1-4cb4-94a1-9164c08c91a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.01482596986750148\n",
      "MAE  : 0.009093535629018712\n",
      "R²   : 0.02370529077288086\n",
      "Var(y_test) : 0.00022514654687217684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Sector\n",
       " Consumer Staples    0.023705\n",
       " dtype: float64,\n",
       " 0.02370529077288086)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_ticker(df, \"PEP\", [ \"Close\", \"Low\", \"High\", \"Open\", \"mom_5\", \"mom_21\", \"vol_5\", \"vol_21\", \"range\", \"volume_z\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "02259f79-e3e5-46b2-a48f-70d97add5426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.01954177952406527\n",
      "MAE  : 0.012451713667786374\n",
      "R²   : 0.027369298213454574\n",
      "Var(y_test) : 0.00039262707445460084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Sector\n",
       " Real Estate    0.027369\n",
       " dtype: float64,\n",
       " 0.027369298213454574)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_ticker(df, \"PLD\", [ \"Close\", \"Low\", \"High\", \"Open\", \"mom_5\", \"mom_21\", \"vol_5\", \"vol_21\", \"range\", \"volume_z\"], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9804f5a4-3f07-4bc7-83c7-fc8fa57913ab",
   "metadata": {},
   "source": [
    "### Spécialisation du modèle par titre et interprétation des R² obtenus\n",
    "\n",
    "Lorsque l’on restreint l’estimation du modèle à un ticker donné, on observe des R² hors-échantillon sensiblement plus élevés, pouvant atteindre des valeurs autour de 0.02–0.03. Ce résultat s’explique par plusieurs mécanismes complémentaires.\n",
    "\n",
    "Premièrement, la spécialisation par titre permet de réduire fortement l’hétérogénéité structurelle présente dans le panel agrégé. Dans un modèle estimé sur l’ensemble des actions, les relations entre caractéristiques (momentum, volatilité, prix, volumes) et rendements futurs peuvent varier considérablement d’un titre à l’autre en raison de différences de modèle économique, de liquidité, de structure actionnariale ou de sensibilité aux facteurs macroéconomiques. En se concentrant sur un seul ticker, le modèle n’a plus à moyenner ces relations hétérogènes et peut apprendre une dynamique plus stable et spécifique.\n",
    "\n",
    "Deuxièmement, certains titres présentent des comportements temporels plus persistants que d’autres (par exemple des effets de momentum plus marqués, une volatilité plus prévisible ou des cycles propres liés à leur activité). Dans ces cas, un modèle dédié est naturellement mieux à même de capter ces régularités idiosyncratiques, ce qui se traduit par une amélioration du pouvoir explicatif mesuré par le R².\n",
    "\n",
    "Troisièmement, le passage à un modèle par ticker modifie implicitement la nature du problème : on ne cherche plus à apprendre une relation “moyenne” valable pour l’ensemble du marché, mais une relation locale, potentiellement plus simple et plus stable dans le temps. Dans ce cadre, un R² de l’ordre de 0.025 reste faible en valeur absolue, mais il est non trivial pour des données de rendements financiers et comparable, voire supérieur, aux ordres de grandeur rapportés dans la littérature pour des modèles de prédiction de rendements.\n",
    "\n",
    "Enfin, il est important de souligner que ces R² plus élevés ne signifient pas nécessairement une exploitabilité économique immédiate. Un modèle par ticker peut capter des régularités spécifiques mais aussi être plus sensible au sur-ajustement et moins robuste hors-échantillon long terme. Néanmoins, ces résultats suggèrent que la prédiction des rendements gagne à être abordée de manière plus désagrégée, soit via des modèles spécifiques par titre, soit via des modèles hiérarchiques ou multi-modèles capables de tenir compte de l’hétérogénéité entre actions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067ab943-ba6a-4932-b329-51aa178c8124",
   "metadata": {},
   "source": [
    "# Conslusion\n",
    "\n",
    "Dans l’article de Gu, Kelly & Xiu (2020), Empirical Asset Pricing via Machine Learning, les auteurs cherchent explicitement à prédire les rendements excédentaires mensuels des actions à partir d’un grand nombre de caractéristiques. Leur protocole expérimental est construit de façon à mimer la situation d’un investisseur réel :\n",
    "\n",
    "les modèles sont entraînés sur une première partie de l’historique, puis évalués hors-échantillon sur une plage de dates ultérieure, distincte et plus récente, éventuellement dans un cadre de type walk-forward (les paramètres peuvent être ré-estimés au fil du temps, mais le test reste sur un bloc “futur” par rapport au train).\n",
    "\n",
    "Autrement dit, chez Gu, Kelly & Xiu, le jeu de test correspond à une période temporelle séparée, sur laquelle on n’utilise que l’information disponible dans le passé pour prédire les rendements du futur. C’est exactement la logique opérationnelle d’un fonds : on veut savoir comment le modèle se comporte quand on avance dans le temps, sans réutiliser, même indirectement, des informations futures dans la phase d’entraînement.\n",
    "\n",
    "Ici, Nous avons adopté une approche différente, davantage pensée comme un exercice de prédiction statistique i.i.d que comme un backtest de trading. Concrètement, on part d’un panel (Ticker,Date) et on construit, pour chaque ligne, une cible définie comme le rendement moyen futur sur \\(H\\) jours à partir des log-rendements :\n",
    "\n",
    "$$\n",
    "\\frac{1}{H}\\sum_{k=1}^{H} r_{t+k}\n",
    "$$\n",
    "\n",
    "pour une date \\(t\\).\n",
    ".\n",
    "\n",
    "Afin de limiter les fuites d’information les plus immédiates, nous ne conservons ensuite qu’une date sur H+1 dans chaque série temporelle (thinning) : cela garantit qu’aucun jour utilisé dans la fenêtre “futur” d’une observation ne réapparaisse comme date d’observation pour une autre.\n",
    "\n",
    "Sur cet ensemble de dates espacées — toujours triées chronologiquement — nous réalisons ensuite un split 60 % / 20 % / 20 % en train / validation / test, en prenant successivement les premières dates (train), les suivantes (validation), puis les dernières (test).\n",
    "\n",
    "Chaque sous-échantillon correspond donc à un bloc temporel sur ces dates retenues, mais, comme une grande partie des jours est volontairement écartée, le test ne représente plus une plage dense et continue d’observations (comme dans un backtest financier), mais plutôt un sous-échantillon éclairci de l’historique, sur lequel nous évaluons la capacité du modèle (XGBoost et autres modèles simples) à capturer la relation entre caractéristiques et rendements moyens futurs.\n",
    "\n",
    "Dans ce cadre, nous obtenons des R² hors-échantillon sensiblement plus élevés que ceux rapportés par Gu, Kelly & Xiu (typiquement autour de 2.5 % dans notre cas pour certains modèles spécialisés sur un ticker, contre des ordres de grandeur de 1–2 % chez eux avec des modèles beaucoup plus sophistiqués). Ces résultats montrent que, d’un point de vue purement prédictif, et malgré l’utilisation de modèles relativement simples, notre protocole de split i.i.d. modifié permet effectivement d’obtenir de bonnes performances en termes de MSE / R².\n",
    "\n",
    "Il convient toutefois de remettre ces ordres de grandeur en perspective. Pris isolément, un R² de l’ordre de 2.5 % peut sembler très faible au regard des standards usuels de la régression appliquée à des phénomènes physiques ou économiques plus stables. Cependant, dans le contexte de la prédiction des rendements financiers, une telle valeur constitue au contraire un résultat notable.\n",
    "\n",
    "Les rendements d’actifs financiers sont caractérisés par un rapport signal–bruit extrêmement faible, une forte composante aléatoire et une instabilité temporelle marquée des relations entre variables explicatives et variable cible. Une grande partie de la variance des rendements est due à des chocs imprévisibles (annonces macroéconomiques, événements géopolitiques, flux de liquidité, réactions comportementales), ce qui limite structurellement le pouvoir explicatif de tout modèle statistique. Dans ce contexte, un R² hors-échantillon positif, même de quelques pourcents, indique déjà que le modèle parvient à extraire un signal prédictif réel au-delà du bruit.\n",
    "\n",
    "Ce point est largement documenté dans la littérature empirique en finance, où de nombreux travaux de référence rapportent des R² hors-échantillon proches de zéro, voire négatifs, pour la prédiction des rendements, y compris à l’aide de modèles sophistiqués. Ainsi, des R² de l’ordre de 1–2 % sont souvent considérés comme substantiels lorsqu’ils sont obtenus de manière robuste et sans fuite d’information. Dans cette perspective, les valeurs observées ici, autour de 2.5 % pour certains modèles spécialisés par ticker, se situent dans la partie haute de ce qui est empiriquement atteignable et témoignent d’une capacité prédictive non triviale.\n",
    "\n",
    "En revanche, il est important de souligner que ces bonnes performances ne sont pas directement exploitables en production par un fonds : un investisseur doit prendre des décisions sur des plages strictement futures par rapport aux données d’entraînement. Pour évaluer une stratégie de manière réaliste, il est donc plus pertinent d’utiliser un schéma de type Gu, Kelly & Xiu, avec un bloc de test séparé dans le futur, voire un protocole de prévision walk-forward sur les dernières années. Dans un tel cadre, nos R² seraient très probablement plus faibles, mais l’évaluation serait beaucoup plus proche de la réalité du métier (prévoir des rendements à venir, pas ré-échantillonner tout l’historique comme s’il était i.i.d.).\n",
    "\n",
    "En résumé, notre protocole de split améliore les performances de prédiction en niveau (R²), mais au prix d’un éloignement par rapport au cadre “production” d’un fonds. Le découpage en bloc temporel futur, tel qu’utilisé par Gu, Kelly & Xiu, est moins flatteur en termes de R² mais beaucoup plus pertinent dès lors que l’objectif est réellement de déployer une stratégie d’investissement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
